{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Encoding Decoding"
      ],
      "metadata": {
        "id": "t-pK0S3deyyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a308Gl0extP",
        "outputId": "5778084e-24d9-467e-dd78-0e13c1093034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: [104, 101, 108, 108, 111]\n",
            "Decoded: hello\n"
          ]
        }
      ],
      "source": [
        "text=\"hello\"\n",
        "encoded=[ord(i) for i in text]\n",
        "print(\"Encoded:\", encoded)\n",
        "decoded=[chr(i) for i in encoded]\n",
        "print(\"Decoded:\", ''.join(decoded))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XfbXoLmifFhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word lavel tokanization"
      ],
      "metadata": {
        "id": "-sOe9icifMHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding\n",
        "text = \"hello world hello\"\n",
        "vocab = {word: idx for idx, word in enumerate(set(text.split()))}\n",
        "encoded = [vocab[word] for word in text.split()]\n",
        "print(\"Encoded:\", encoded)\n",
        "\n",
        "# Decoding\n",
        "inv_vocab = {idx: word for word, idx in vocab.items()}\n",
        "decoded = ' '.join([inv_vocab[idx] for idx in encoded])\n",
        "print(\"Decoded:\", decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmuGLPVXfQUH",
        "outputId": "bb51eddb-0f51-4425-89dc-45c140eec4c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: [0, 1, 0]\n",
            "Decoded: hello world hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder And Decoder Implementation in Deep Learning"
      ],
      "metadata": {
        "id": "kA_wwYEVg4Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "\n",
        "# Dummy parameters\n",
        "num_encoder_tokens = 100  # size of input vocabulary\n",
        "num_decoder_tokens = 120  # size of output vocabulary\n",
        "latent_dim = 256  # size of the hidden state\n",
        "\n",
        "# ---------------------\n",
        "# 1. Define the Encoder\n",
        "# ---------------------\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))  # (batch_size, timesteps, features)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# Save the encoder states\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# ---------------------\n",
        "# 2. Define the Decoder\n",
        "# ---------------------\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))  # shifted right version of target sentence\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# ---------------------\n",
        "# 3. Combine into a Model\n",
        "# ---------------------\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "NBFhKfU9fSQz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JyqMfNFShDxZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}